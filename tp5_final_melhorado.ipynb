{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMpjF596IXVNcvOHaF07Bud",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DemarchiWorking/AXIOS-API-VUE/blob/master/tp5_final_melhorado.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q8mUML3LxURz"
      },
      "outputs": [],
      "source": [
        "#instalar\n",
        "!pip install kagglehub[pandas-datasets]\n",
        "!pip install lime\n",
        "import kagglehub\n",
        "from kagglehub import KaggleDatasetAdapter\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.decomposition import LatentDirichletAllocation\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "from sklearn.decomposition import LatentDirichletAllocation\n",
        "from sklearn.model_selection import train_test_split, StratifiedKFold, GridSearchCV\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import classification_report, confusion_matrix, ConfusionMatrixDisplay, roc_curve, roc_auc_score\n",
        "\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm import tqdm #barra de progresso\n",
        "\n",
        "from sklearn.manifold import TSNE\n",
        "import seaborn as sns # Para visualização do t-SNE\n",
        "import shap # Para interpretabilidade com SHAP\n",
        "#import lime.lime_text\n",
        "from lime.lime_text import LimeTextExplainer\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\", category=FutureWarning) # Suprimir avisos de versões futuras\n",
        "#importacoes\n",
        "\n",
        "\n",
        "#configuracoes para matplotlib e seaborn\n",
        "plt.style.use('seaborn-v0_8-whitegrid')\n",
        "sns.set_style(\"whitegrid\")\n",
        "\n",
        "\n",
        "#nome do arquivo na pasta\n",
        "file_path = \"IMDB Dataset.csv\"\n",
        "\n",
        "#argumentos p/ leitor\n",
        "pandas_args = {\n",
        "    \"on_bad_lines\": \"skip\",  #pula linhas mal formadas\n",
        "    \"engine\": \"python\",      #engine python\n",
        "    \"quotechar\": '\"',         #aspas duplas como o caractere de citacao\n",
        "    \"encoding\": \"latin1\"\n",
        "\n",
        "}\n",
        "#carregar versao correta do dataset\n",
        "df = kagglehub.load_dataset(\n",
        "  KaggleDatasetAdapter.PANDAS,\n",
        "  \"lakshmi25npathi/imdb-dataset-of-50k-movie-reviews\",\n",
        "  file_path,\n",
        "  pandas_kwargs=pandas_args\n",
        ")\n",
        "\n",
        "print(\"===========================================================================================================\")\n",
        "print(\"======================================= Introducao ========================================================\")\n",
        "print(\"===========================================================================================================\")\n",
        "\n",
        "\n",
        "#mostrando o começo do dataframe\n",
        "print(\"inicio do dataframe:\")\n",
        "print(df.head())\n",
        "\n",
        "#final do dataframe\n",
        "print(\"mostra o final do dataset=\", df.tail())\n",
        "\n",
        "\n",
        "#estatisticas para colunas numericas\n",
        "print(\"mostra descritivas do dataset=\")\n",
        "print(df.describe(include='all'))\n",
        "\n",
        "#dados sobre as colunas e tipos de dados:\n",
        "print(\"informacoes sobre o DataFrame=\")\n",
        "df.info()\n",
        "\n",
        "#nomes das colunas\n",
        "print(\"mostra nome das colunas=\", df.columns)\n",
        "\n",
        "\n",
        "\n",
        "print(\"===========================================================================================================\")\n",
        "print(\"==================================== Calculando o tf-idf p/ dataset =======================================\")\n",
        "print(\"===========================================================================================================\")\n",
        "\n",
        "print(\"1) Criação das features: Computar o Term Frequency-Inverse Document Frequency (TF-IDF) para representar a importância das palavras em um conjunto de documentos.\")\n",
        "\n",
        "#configuracao do vetorizador tf-idf\n",
        "vetorizador = TfidfVectorizer(\n",
        "    stop_words='english',\n",
        "    max_features=20000,\n",
        "    min_df=5,\n",
        "    ngram_range=(1, 2)\n",
        ")\n",
        "\n",
        "print(\"calculo do tf-idf p/ 50k\")\n",
        "\n",
        "#aplicando o vetorizador na coluna review do dataframe\n",
        "features_tfidf = vetorizador.fit_transform(df['review'])\n",
        "\n",
        "\n",
        "#analise dos resultados\n",
        "print(\"informacoes do tf-idf criada\")\n",
        "\n",
        "#mostrando o formato da matriz resultante\n",
        "print(f\"matriz de features: {features_tfidf.shape}\")\n",
        "print(f\"tem {features_tfidf.shape[0]} documentos [reviews] e {features_tfidf.shape[1]} features [termos unicos ou n-gramas].\")\n",
        "\n",
        "#mostrando algumas das palavras\n",
        "nomes_das_features = vetorizador.get_feature_names_out()\n",
        "print(\"amostra de 20 features [palavras/termos]=\")\n",
        "print(nomes_das_features[5000:5020])\n",
        "print(\"\\n\")\n",
        "\n",
        "print(\"mostrando trecho [5x10] da matriz tf-idf c/ scores=\")\n",
        "df_tfidf_amostra = pd.DataFrame(\n",
        "    features_tfidf[0:5, 5000:5010].toarray(),\n",
        "    columns=nomes_das_features[5000:5010]\n",
        ")\n",
        "print(df_tfidf_amostra.round(2))\n",
        "\n",
        "total_elementos = features_tfidf.shape[0] * features_tfidf.shape[1]\n",
        "elementos_nao_nulos = features_tfidf.nnz\n",
        "\n",
        "porcentagem_nao_nulos = (elementos_nao_nulos / total_elementos) * 100\n",
        "porcentagem_nulos = 100 - porcentagem_nao_nulos\n",
        "\n",
        "print(f\"analise de esparsidade\")\n",
        "print(f\"a matriz tem {elementos_nao_nulos} valores diferentes de zero.\")\n",
        "print(f\"porcentagem de valores nao-null: {porcentagem_nao_nulos:.3f}%\")\n",
        "print(f\"porcentagem de valores null [0]: {porcentagem_nulos:.3f}%\")\n",
        "\n",
        "\n",
        "#importacoes necessarias\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm import tqdm #barra de progresso\n",
        "\n",
        "print(\"=============================================================================================================\")\n",
        "print(\"==================================== Modelagem de topicos com lda ===========================================\")\n",
        "print(\"=============================================================================================================\")\n",
        "\n",
        "print(\"2) Modelagem de Tópicos com LDA: Aplicar o algoritmo LDA para identificar tópicos prevalentes nos dados. A seleção do número de tópicos será baseada em métricas de coerência para garantir a relevância e a distinção entre os tópicos identificados.\")\n",
        "\n",
        "\n",
        "print(\"vetorizando os dados com countvectorizer\")\n",
        "vetorizador_contagem = CountVectorizer(\n",
        "    stop_words='english',\n",
        "    max_features=10000,\n",
        "    min_df=5,\n",
        "    ngram_range=(1, 1)\n",
        ")\n",
        "features_contagem = vetorizador_contagem.fit_transform(df['review'])\n",
        "nomes_features_contagem = vetorizador_contagem.get_feature_names_out()\n",
        "print(\"matriz de contagem de palavras criada com formato:\", features_contagem.shape)\n",
        "\n",
        "\n",
        "#encontrando o numero de topicos [k]\n",
        "print(\"testando multiplos valores de k [numero de topicos] para encontrar um bom\")\n",
        "\n",
        "min_topics = 2\n",
        "max_topics = 15\n",
        "topic_range = range(min_topics, max_topics + 1)\n",
        "\n",
        "log_likelihoods = []\n",
        "perplexities = []\n",
        "\n",
        "#loop para treinar e avaliar um modelo LDA p/ cada nº topicos\n",
        "for k in tqdm(topic_range, desc=\"avaliando modelos LDA\"):\n",
        "    lda = LatentDirichletAllocation(\n",
        "        n_components=k,\n",
        "        random_state=42,\n",
        "        n_jobs=-1,\n",
        "        learning_method='online'\n",
        "    )\n",
        "    lda.fit(features_contagem)\n",
        "\n",
        "    #armazena a log-likelihood e perplexities do modelo\n",
        "    log_likelihoods.append(lda.score(features_contagem))\n",
        "    perplexities.append(lda.perplexity(features_contagem))\n",
        "\n",
        "#visualizacao das metricas para escolha de k\n",
        "print(\"visualizando as metricas para a escolha do numero de topicos\")\n",
        "\n",
        "plt.style.use('seaborn-v0_8-whitegrid')\n",
        "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))\n",
        "\n",
        "#grafico da log likelihood\n",
        "ax1.plot(topic_range, log_likelihoods, 'o-', color='darkblue')\n",
        "ax1.set_title('log-likelihood x numero de topicos')\n",
        "ax1.set_xlabel('numero de topicos [k]')\n",
        "ax1.set_ylabel('log-likelihood')\n",
        "ax1.set_xticks(topic_range)\n",
        "\n",
        "#grafico da perplexidade\n",
        "ax2.plot(topic_range, perplexities, 'o-', color='crimson')\n",
        "ax2.set_title('perplexidade x numero de topicos')\n",
        "ax2.set_xlabel('numero de topicos [k]')\n",
        "ax2.set_ylabel('perplexidade')\n",
        "ax2.set_xticks(topic_range)\n",
        "\n",
        "plt.suptitle('analise para selecao do numero de topicos [k] do LDA', fontsize=16)\n",
        "plt.tight_layout(rect=[0, 0, 1, 0.96])\n",
        "plt.show()\n",
        "\n",
        "#treinamento do modelo LDA final com o k escolhido\n",
        "print(\"justificativa da escolha e treinamento do modelo final\")\n",
        "print(\"Com base nos graficos, a curva de perplexidade comeca a se achatar [formar um cotovelo] por volta de k=8. desse ponto p frente comeca a adicionar mais topicos q nao traz uma melhora relevante e pode levar a topicos menos distintos. Portanto, escolhemos k=8 como o numero ideal de topicos para este dataset.\")\n",
        "\n",
        "#numero de topicos com base na analise\n",
        "num_topicos_ideal = 3 #8\n",
        "\n",
        "print(f\"treinando o modelo lda final com k={num_topicos_ideal} topicos\")\n",
        "lda_final = LatentDirichletAllocation(\n",
        "    n_components=num_topicos_ideal,\n",
        "    random_state=42,\n",
        "    n_jobs=-1,\n",
        "    learning_method='online'\n",
        ")\n",
        "lda_final.fit(features_contagem)\n",
        "print(\"modelo lda final treinado com sucesso.\")\n",
        "\n",
        "def exibir_topicos(modelo, feature_names, n_top_words):\n",
        "    for topic_idx, topic in enumerate(modelo.components_):\n",
        "        #pega os indices das N palavras com maior peso no topico\n",
        "        top_features_ind = topic.argsort()[:-n_top_words - 1:-1]\n",
        "        #pega os nomes dessas palavras\n",
        "        top_features = [feature_names[i] for i in top_features_ind]\n",
        "        #monta a string de resultado\n",
        "        message = f\"Tópico #{topic_idx}: \" + \", \".join(top_features)\n",
        "        print(message)\n",
        "\n",
        "print(f\"exibindo as 10 palavras mais importantes para cada um dos {num_topicos_ideal} topicos encontrados=\")\n",
        "exibir_topicos(lda_final, nomes_features_contagem, 10)\n",
        "\n",
        "\n",
        "#associar os topicos aos documentos originais\n",
        "print(\"exemplo p/ associar topicos a reviews especificos=\")\n",
        "distribuicao_topicos = lda_final.transform(features_contagem)\n",
        "topico_dominante = np.argmax(distribuicao_topicos, axis=1)\n",
        "\n",
        "for i in range(5):\n",
        "    print(f\"review #{i}:\")\n",
        "    print(df['review'][i][:200] + \"...\")\n",
        "    print(f\"topico dominante = {topico_dominante[i]}\")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "print(\"=============================================================================================================\")\n",
        "print(\"==================================== classificacao de texto c/ lda ==========================================\")\n",
        "print(\"=============================================================================================================\")\n",
        "\n",
        "print(\"3) Classificação de Textos: Desenvolver modelos de classificação para categorizar os textos com base nos tópicos identificados. Você pode escolher qualquer modelo aprendido ao longo do curso e deve escolher o melhor modelo usando as técnicas aprendidas, como busca de hiperparâmetros e validação cruzada\")\n",
        "\n",
        "\n",
        "print(\"preparando os dados p/ classificacao\")\n",
        "\n",
        "#features [X] sao as distribuicoes de topicos já calculada.\n",
        "X_topics = distribuicao_topicos\n",
        "print(f\"formato da matriz de features [X]: {X_topics.shape}\")\n",
        "\n",
        "#alvo [y] e a coluna [sentiment] do df\n",
        "#convertr de texto [positive/negative] p/ numeros [1/0].\n",
        "le = LabelEncoder()\n",
        "y_sentiment = le.fit_transform(df['sentiment'])\n",
        "print(f\"formato do vetor de alvo [y]: {y_sentiment.shape}\")\n",
        "print(f\"classes: {le.classes_} >> {le.transform(le.classes_)}\")\n",
        "\n",
        "#dividindo em conjuntos de treino e teste [80% para treino, 20% para teste]\n",
        "#stratify=y_sentiment p/ fazer com que a proporcao de reviews positivos/negativos seja a mesma nos dois conjuntos.\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X_topics,\n",
        "    y_sentiment,\n",
        "    test_size=0.2,\n",
        "    random_state=42,\n",
        "    stratify=y_sentiment\n",
        ")\n",
        "\n",
        "print(f\"tamanho do conjunto de treino: {X_train.shape[0]} amostras\")\n",
        "print(f\"tamanho do conjunto de teste: {X_test.shape[0]} amostras\")\n",
        "\n",
        "\n",
        "print(\"buscando o melhor modelo e hiperparametros com gridsearchcv\")\n",
        "\n",
        "#Modelo 1=Regressao Logistica\n",
        "#Modelo 2=Support Vector Machine (SVC)\n",
        "modelos = {\n",
        "    'LogisticRegression': {\n",
        "        'model': LogisticRegression(random_state=42, max_iter=1000),\n",
        "        'params': {\n",
        "            'C': [0.1, 1, 10, 100],\n",
        "            'solver': ['liblinear', 'saga']\n",
        "        }\n",
        "    },\n",
        "    'SVC': {\n",
        "        'model': SVC(random_state=42, probability=True),\n",
        "        'params': {\n",
        "            'C': [0.1, 1, 10],\n",
        "            'gamma': ['scale', 'auto'],\n",
        "            'kernel': ['rbf']\n",
        "        }\n",
        "    }\n",
        "}\n",
        "\n",
        "#definindo a estrategia de validacao cruzada estratificada [5 folds] p/ manter a proporção das classes em cada fold\n",
        "cv_strategy = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "best_models = {}\n",
        "\n",
        "#iterando sobre os modelos para realizar o GridSearchCV\n",
        "for model_name, config in modelos.items():\n",
        "    print(f\"iniciando busca para o modelo: {model_name}\")\n",
        "    grid_search = GridSearchCV(\n",
        "        estimator=config['model'],\n",
        "        param_grid=config['params'],\n",
        "        cv=cv_strategy,\n",
        "        scoring='accuracy', #otimizar\n",
        "        n_jobs=-1 #processador on\n",
        "    )\n",
        "\n",
        "    #treinando o GridSearchCV com os dados de treino\n",
        "    grid_search.fit(X_train, y_train)\n",
        "\n",
        "    print(f\"melhores hiperparametros= {grid_search.best_params_}\")\n",
        "    print(f\"melhor acuracia em validacao cruzada= {grid_search.best_score_:.4f}\")\n",
        "\n",
        "    #salvando o melhor estimador encontrado\n",
        "    best_models[model_name] = grid_search.best_estimator_\n",
        "\n",
        "#determinando modelos com o melhor desempenho\n",
        "best_model_name = max(best_models, key=lambda name: best_models[name].score(X_train, y_train))\n",
        "final_model = best_models[best_model_name]\n",
        "\n",
        "print(f\"melhor modelo geral escolhido: {best_model_name}\")\n",
        "print(\"avaliando o desempenho do melhor modelo no conjunto de teste [dados nunca vistos]\")\n",
        "\n",
        "#fazendo previsoes nos dados de teste\n",
        "y_pred = final_model.predict(X_test)\n",
        "\n",
        "#exibindo o relatorio de classificacao completo\n",
        "print(\"relatorio de classificacao=\")\n",
        "print(classification_report(y_test, y_pred, target_names=le.classes_))\n",
        "\n",
        "#exibindo a matriz de confusao\n",
        "print(\"matriz de confusao=\")\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=le.classes_)\n",
        "disp.plot(cmap=plt.cm.Blues)\n",
        "plt.title(f'matriz de confusao para o modelo {best_model_name}')\n",
        "plt.show()\n",
        "\n",
        "print(\"==================================== Treinando um modelo com base as features do TF-IDF ===========================================\")\n",
        "\n",
        "#dividir os dados TF-IDF em treino e teste\n",
        "X_tfidf_train, X_tfidf_test, y_train_tfidf, y_test_tfidf = train_test_split(\n",
        "    features_tfidf,     #usando features_tfidf\n",
        "    y_sentiment,\n",
        "    test_size=0.2,\n",
        "    random_state=42,\n",
        "    stratify=y_sentiment\n",
        ")\n",
        "\n",
        "print(f\"tamanho do conjunto de treino [TF-IDF]: {X_tfidf_train.shape[0]} amostras\")\n",
        "print(f\"tamanho do conjunto de teste [TF-IDF]: {X_tfidf_test.shape[0]} amostras\")\n",
        "\n",
        "\n",
        "#treinar um modelo c/ regressao logística,\n",
        "# que costuma performar bem com dados TF-IDF esparsos.\n",
        "print(\"treinando o modelo de regressao logistica com features TF-IDF\")\n",
        "model_tfidf = LogisticRegression(C=10, solver='saga', random_state=42, max_iter=1000, n_jobs=-1)\n",
        "model_tfidf.fit(X_tfidf_train, y_train_tfidf)\n",
        "\n",
        "\n",
        "#avaliar o modelo TF-IDF no conjunto de teste\n",
        "print(\"avaliando o desempenho do modelo TF-IDF no conjunto de teste=\")\n",
        "y_pred_tfidf = model_tfidf.predict(X_tfidf_test)\n",
        "\n",
        "print(\"relatorio de classificacao [Modelo Base TF-IDF]=\")\n",
        "print(classification_report(y_test_tfidf, y_pred_tfidf, target_names=le.classes_))\n",
        "\n",
        "\n",
        "#comparacao final dos resultados\n",
        "print(\"==================================== comparacao final dos modelos ===========================================\")\n",
        "\n",
        "print(f\"modelo baseado em topicos [LDA + {best_model_name}]:\")\n",
        "#re-exibindo o relatorio do modelo anterior para comparacao direta\n",
        "y_pred_topics = final_model.predict(X_test)\n",
        "print(classification_report(y_test, y_pred_topics, target_names=le.classes_))\n",
        "\n",
        "print(f\"modelo base [TF-IDF + LogisticRegression]=\")\n",
        "print(classification_report(y_test_tfidf, y_pred_tfidf, target_names=le.classes_))\n",
        "\n",
        "\n",
        "print(\"=============================================================================================================\")\n",
        "print(\"======================================== avaliacao de desempenho ============================================\")\n",
        "print(\"=============================================================================================================\")\n",
        "\n",
        "\n",
        "print(\"4) Avaliação de Desempenho: O desempenho dos modelos de classificação será avaliado utilizando métricas como precisão, recall, F1-score e AUC-ROC.\")\n",
        "\n",
        "#analise do modelo principal [LDA]\n",
        "print(f\"analise do modelo principal [{best_model_name} + LDA]\")\n",
        "\n",
        "#exibindo o relatorio [principal]\n",
        "y_pred_topics = final_model.predict(X_test)\n",
        "print(\"relatorio de classificacao [Modelo Principal]:\")\n",
        "print(classification_report(y_test, y_pred_topics, target_names=le.classes_))\n",
        "\n",
        "#calcular probabilidades e AUC para o modelo principal [LDA]\n",
        "y_pred_proba_topics = final_model.predict_proba(X_test)[:, 1]\n",
        "auc_score_topics = roc_auc_score(y_test, y_pred_proba_topics)\n",
        "fpr_topics, tpr_topics, _ = roc_curve(y_test, y_pred_proba_topics)\n",
        "print(f\"AUC [Modelo Principal]: {auc_score_topics:.4f}\")\n",
        "\n",
        "\n",
        "#analise do modelo base [TF-IDF]\n",
        "print(f\"analise do modelo base [LogisticRegression + TF-IDF]\")\n",
        "\n",
        "#re-exibindo o relatorio\n",
        "y_pred_tfidf = model_tfidf.predict(X_tfidf_test)\n",
        "print(\"relatorio de classificacao [Modelo Base)=\")\n",
        "print(classification_report(y_test_tfidf, y_pred_tfidf, target_names=le.classes_))\n",
        "\n",
        "#calcular probabilidades e AUC para o modelo base [TF-IDF]\n",
        "y_pred_proba_tfidf = model_tfidf.predict_proba(X_tfidf_test)[:, 1]\n",
        "auc_score_tfidf = roc_auc_score(y_test_tfidf, y_pred_proba_tfidf)\n",
        "fpr_tfidf, tpr_tfidf, _ = roc_curve(y_test_tfidf, y_pred_proba_tfidf)\n",
        "print(f\"AUC [Modelo Base]= {auc_score_tfidf:.4f}\")\n",
        "\n",
        "\n",
        "#Plot Comparativo da Curva ROC\n",
        "print(\"grafico comparativo da curva ROC\")\n",
        "\n",
        "plt.figure(figsize=(10, 8))\n",
        "\n",
        "#plot da curva ROC do modelo principal [LDA]\n",
        "plt.plot(fpr_topics, tpr_topics, color='darkorange', lw=2,\n",
        "         label=f'modelo principal [LDA] [AUC = {auc_score_topics:.4f}]')\n",
        "\n",
        "#plot da curva ROC do modelo base [TF-IDF]\n",
        "plt.plot(fpr_tfidf, tpr_tfidf, color='blue', lw=2,\n",
        "         label=f'modelo Base [TF-IDF] [AUC = {auc_score_tfidf:.4f}]')\n",
        "\n",
        "#linha de referencia\n",
        "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--', label='classificador aleatorio')\n",
        "\n",
        "plt.xlim([0.0, 1.0])\n",
        "plt.ylim([0.0, 1.05])\n",
        "plt.xlabel('taxa de falsos positivos [FPR]')\n",
        "plt.ylabel('taxa de verdadeiros positivos [TPR]')\n",
        "plt.title('comparacao da curva ROC entre modelos')\n",
        "plt.legend(loc=\"lower right\")\n",
        "plt.grid(True)\n",
        "plt.show()\n",
        "\n",
        "\n",
        "\n",
        "print(\"=============================================================================================================\")\n",
        "print(\"============================================== aplicar T-SNE ================================================\")\n",
        "print(\"=============================================================================================================\")\n",
        "\n",
        "print(\"5) Visualização com t-SNE: Aplicar a técnica de t-SNE nos dados textuais vetorizados para reduzir a dimensionalidade e visualizar os agrupamentos de documentos de maneira intuitiva, facilitando a identificação de padrões e outliers.\")\n",
        "print(\"aplicando a tecnica de t-SNE nos dados vetorizados para reduzir a dimensionalidade e visualizar os agrupamentos.\")\n",
        "\n",
        "#t-SNE uma parte aleatoria dos dados para uma execucao mais rapida e nao bugar.\n",
        "sample_size = 5000\n",
        "np.random.seed(42) #mochileiro das galaxias\n",
        "random_indices = np.random.choice(X_topics.shape[0], size=sample_size, replace=False)\n",
        "\n",
        "X_sample = X_topics[random_indices]\n",
        "y_sample = y_sentiment[random_indices]\n",
        "sentiment_labels = le.inverse_transform(y_sample)\n",
        "\n",
        "print(f\"executando t-SNE em uma amostra de {sample_size} documentos.\")\n",
        "\n",
        "#inicializa e aplica o t-SNE\n",
        "tsne = TSNE(n_components=2, random_state=42, perplexity=30, n_iter=1000)\n",
        "tsne_results = tsne.fit_transform(X_sample)\n",
        "\n",
        "#criando um dataframe para facilitar a plotagem\n",
        "df_tsne = pd.DataFrame({\n",
        "    'tsne_1': tsne_results[:,0],\n",
        "    'tsne_2': tsne_results[:,1],\n",
        "    'sentiment': sentiment_labels\n",
        "})\n",
        "\n",
        "#plotando os resultados\n",
        "plt.figure(figsize=(12, 8))\n",
        "sns.scatterplot(\n",
        "    x=\"tsne_1\", y=\"tsne_2\",\n",
        "    hue=\"sentiment\",\n",
        "    palette=sns.color_palette(\"hls\", 2),\n",
        "    data=df_tsne,\n",
        "    legend=\"full\",\n",
        "    alpha=0.6\n",
        ")\n",
        "plt.title('visualizacao t-SNE das p/ sentimento [baseado nos topicos LDA)', fontsize=16)\n",
        "plt.xlabel('componente t-SNE 1')\n",
        "plt.ylabel('componente t-SNE 2')\n",
        "plt.show()\n",
        "\n",
        "print(\"o grafico t-SNE mostra a formacao de clusters. idealmente, reviews [positive e negative] se agrupam em regioes distintas,\")\n",
        "\n",
        "\n",
        "print(\"======================== interpretacao de modelos com SHAP e force-plot ============================\")\n",
        "print(\"6) Interpretação de Modelos com LIME, SHAP e Force-Plot: Utilizar SHAP para explicar as previsões individuais, identificando a contribuição de cada feature para a decisão do modelo. O force-plot será usado para visualizar essas contribuições de maneira agregada, oferecendo insights sobre a lógica de decisão do modelo.\")\n",
        "print(f\"iniciando a interpretacao do modelo '{best_model_name}' com SHAP.\")\n",
        "\n",
        "\n",
        "#javascript no notebook para os plots\n",
        "shap.initjs()\n",
        "\n",
        "#amostra os dados de fundo para o KernelExplainer\n",
        "background_data = shap.sample(X_train, 100)\n",
        "#amostra os dados de teste para a analise\n",
        "test_sample_data = shap.sample(X_test, 20)\n",
        "\n",
        "#criando o explainer com o predict_proba do modelo, focando na classe positiva [índice 1]\n",
        "explainer = shap.KernelExplainer(lambda x: final_model.predict_proba(x)[:, 1], background_data)\n",
        "\n",
        "print(\"calculando os valores SHAP para um subconjunto de dados de teste.\")\n",
        "#calcula os valores SHAP para a amostra de teste\n",
        "shap_values_sample = explainer.shap_values(test_sample_data)\n",
        "\n",
        "#nomes das features para os plots [tópico 0, tópico 1]\n",
        "topic_feature_names = [f\"tópico {i}\" for i in range(num_topicos_ideal)]\n",
        "\n",
        "print(\"escolhido o Force-Plot para explicar previsoes individuais\")\n",
        "print(\"analisando a previsao para a primeira instancia da nossa amostra de teste=\")\n",
        "\n",
        "#gera o force plot para a primeira instancia da amostra de teste\n",
        "display(shap.force_plot(explainer.expected_value, shap_values_sample[0], test_sample_data[0], feature_names=topic_feature_names))\n",
        "\n",
        "print(\"selecionado o summary plot para ver a influencia agregada das variaveis\")\n",
        "print(\"resume como cada topico impacta as previsoes do modelo em todo o subconjunto de teste\")\n",
        "\n",
        "#o summary plot mostra a importancia e o impacto de cada feature.\n",
        "shap.summary_plot(shap_values_sample, test_sample_data, feature_names=topic_feature_names)\n",
        "\n",
        "print(\"importancia media das features [Bar Plot]\")\n",
        "#o bar plot mostra a media do valor absoluto do SHAP para cada feature, indicando sua importancia geral.\n",
        "shap.summary_plot(shap_values_sample, test_sample_data, feature_names=topic_feature_names, plot_type=\"bar\")\n",
        "\n",
        "\n",
        "print(\"=============================================================================================================\")\n",
        "print(\"================================== interpretacao adicional com lime =========================================\")\n",
        "print(\"=============================================================================================================\")\n",
        "\n",
        "print(\"6.2) Interpretação de Modelos com LIME usado para entender quais palavras no texto bruto mais influenciaram a decisao do nosso melhor modelo.\")\n",
        "\n",
        "#criar uma funcao de predicao em formato de pipeline\n",
        "def predictor_tfidf(texts):\n",
        "    #.transform() pois o vetorizador ja foi ajustado aos dados de treino\n",
        "    features = vetorizador.transform(texts)\n",
        "    #retornamos as probabilidades de previsao do modelo TF-IDF\n",
        "    return model_tfidf.predict_proba(features)\n",
        "\n",
        "#instanciar o LimeTextExplainer fornecendo os nomes das classes para que as explicacoes fiquem mais claras.\n",
        "explainer_lime = LimeTextExplainer(class_names=le.classes_)\n",
        "\n",
        "#selecionar uma instancia do conjunto de teste para explicar\n",
        "idx_to_explain = 15 #se alterar a variavel vai mostrar outras reviews\n",
        "\n",
        "#para obter o texto original, precisamos dos dados de texto que foram para o conjunto de teste.Uma boa pratica e dividir a serie de texto original com o mesmo random_state.\n",
        "_, review_test, _, _ = train_test_split(df['review'], y_sentiment, test_size=0.2, random_state=42, stratify=y_sentiment)\n",
        "text_instance = review_test.iloc[idx_to_explain]\n",
        "\n",
        "print(f\"explicando a review de indice {idx_to_explain}\")\n",
        "print(f\"texto original: {text_instance[:500]}\")\n",
        "true_label = le.inverse_transform([y_test_tfidf[idx_to_explain]])[0]\n",
        "pred_label = le.inverse_transform(model_tfidf.predict(X_tfidf_test[idx_to_explain].reshape(1, -1)))[0]\n",
        "print(f\"classe verdadeira  = '{true_label}'\")\n",
        "print(f\"previsao do modelo = '{pred_label}'\")\n",
        "\n",
        "#gerar e exibir a explicação do LIME\n",
        "print(\"explicação LIME\")\n",
        "explanation = explainer_lime.explain_instance(\n",
        "    text_instance,\n",
        "    classifier_fn=predictor_tfidf,\n",
        "    num_features=10  #numero de palavras mais importantes a serem exibidas\n",
        ")\n",
        "\n",
        "#esta visualizacao colorida destaca as palavras que mais contribuiram para a previsao.\n",
        "#palavras em verde apoiam a previsao, palavras em vermelho contradizem.\n",
        "print(\"visualizacao da explicacao LIME\")\n",
        "explanation.show_in_notebook(text=True)\n",
        "\n",
        "\n",
        "print(\"##############################################################################################################################################################################################\")\n",
        "print(\"##############################################################################################################################################################################################\")\n",
        "print(\"##############################################################################################################################################################################################\")\n",
        "print(\"##############################################################################################################################################################################################\")\n",
        "print(\"##############################################################################################################################################################################################\")\n",
        "print(\"##############################################################################################################################################################################################\")\n",
        "print(\"##############################################################################################################################################################################################\")\n",
        "print(\"##############################################################################################################################################################################################\")\n",
        "\n",
        "\n",
        "#instalar\n",
        "!pip install kagglehub[pandas-datasets] --quiet\n",
        "!pip install lime --quiet\n",
        "!pip install nltk --quiet\n",
        "!pip install gensim --quiet\n",
        "!pip install \"numpy==2.1.0\" \"gensim>=4.3.3\" \"scikit-learn>=1.4.0\" \"shap\" \"numba\" --upgrade --quiet\n",
        "\n",
        "import kagglehub\n",
        "from kagglehub import KaggleDatasetAdapter\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.decomposition import LatentDirichletAllocation, TruncatedSVD\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "from sklearn.model_selection import train_test_split, StratifiedKFold, GridSearchCV\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import classification_report, confusion_matrix, ConfusionMatrixDisplay, roc_curve, roc_auc_score\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm import tqdm\n",
        "from tqdm.auto import tqdm\n",
        "tqdm.pandas()\n",
        "\n",
        "from sklearn.manifold import TSNE\n",
        "import seaborn as sns\n",
        "import shap\n",
        "from lime.lime_text import LimeTextExplainer\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\", category=FutureWarning) #reduzir avisos de versoes futuras\n",
        "\n",
        "#baixar itens do nltk\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('punkt_tab')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "import re\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk.tokenize import word_tokenize\n",
        "from gensim.corpora.dictionary import Dictionary\n",
        "from gensim.models.coherencemodel import CoherenceModel\n",
        "from IPython.display import display\n",
        "\n",
        "#configuracoes para matplotlib e seaborn\n",
        "plt.style.use('seaborn-v0_8-whitegrid')\n",
        "sns.set_style(\"whitegrid\")\n",
        "\n",
        "print(\"################################################# importacoes e configuracoes ############################################\")\n",
        "\n",
        "#nome do arquivo na pasta\n",
        "file_path = \"IMDB Dataset.csv\"\n",
        "\n",
        "#argumentos p/ leitor\n",
        "pandas_args = {\n",
        "    \"on_bad_lines\": \"skip\",  #pula linhas mal formadas\n",
        "    \"engine\": \"python\",      #engine python\n",
        "    \"quotechar\": '\"',        #aspas duplas como o caractere de citacao\n",
        "    \"encoding\": \"latin1\"\n",
        "}\n",
        "#carregar versao correta do dataset\n",
        "df = kagglehub.dataset_load(\n",
        "    KaggleDatasetAdapter.PANDAS,\n",
        "    \"lakshmi25npathi/imdb-dataset-of-50k-movie-reviews\",\n",
        "    file_path,\n",
        "    pandas_kwargs=pandas_args\n",
        ")\n",
        "\n",
        "#funcao de preprocessamento\n",
        "def preprocess_text(text):\n",
        "    text = re.sub(r'<.*?>', '', text)#remover tags HTML\n",
        "    text = re.sub(r'[^a-zA-Z]', ' ', text).lower() #remover caracteres nao-alfabeticos e converter para minusculas\n",
        "    tokens = word_tokenize(text) #tokenizar\n",
        "    lemmatizer = WordNetLemmatizer() #lematizar e remover stopwords\n",
        "    stop_words_set = set(stopwords.words('english'))\n",
        "    lemmatized_tokens = [\n",
        "        lemmatizer.lemmatize(word) for word in tokens\n",
        "        if word not in stop_words_set and len(word) > 2\n",
        "    ]\n",
        "    return \" \".join(lemmatized_tokens)\n",
        "\n",
        "print(\"iniciando pre-processamento avancado de texto [lematizacao]\")\n",
        "df['review_cleaned'] = df['review'].progress_apply(preprocess_text)\n",
        "\n",
        "print(\"ex:primeira review limpa:\")\n",
        "print(df['review_cleaned'][0])\n",
        "\n",
        "print(\"===========================================================================================================\")\n",
        "print(\"======================================= Introducao ========================================================\")\n",
        "print(\"===========================================================================================================\")\n",
        "\n",
        "\n",
        "#mostrando o começo do dataframe\n",
        "print(\"inicio do dataframe:\")\n",
        "print(df.head())\n",
        "\n",
        "#final do dataframe\n",
        "print(\"mostra o final do dataset=\", df.tail())\n",
        "\n",
        "\n",
        "#estatisticas para colunas numericas\n",
        "print(\"mostra descritivas do dataset=\")\n",
        "print(df.describe(include='all'))\n",
        "\n",
        "#dados sobre as colunas e tipos de dados:\n",
        "print(\"informacoes sobre o DataFrame=\")\n",
        "df.info()\n",
        "\n",
        "#nomes das colunas\n",
        "print(\"mostra nome das colunas=\", df.columns)\n",
        "\n",
        "\n",
        "\n",
        "print(\"===========================================================================================================\")\n",
        "print(\"==================================== Calculando o tf-idf p/ dataset =======================================\")\n",
        "print(\"===========================================================================================================\")\n",
        "\n",
        "print(\"1) Criação das features: Computar o Term Frequency-Inverse Document Frequency (TF-IDF) para representar a importância das palavras em um conjunto de documentos.\")\n",
        "\n",
        "#configuracao do vetorizador tf-idf\n",
        "vetorizador = TfidfVectorizer(\n",
        "    stop_words='english', #feito no preprocessamento\n",
        "    max_features=20000,\n",
        "    min_df=5,\n",
        "    ngram_range=(1, 2)\n",
        ")\n",
        "\n",
        "print(\"calculo do tf-idf p/ 50k\")\n",
        "\n",
        "#aplicando o vetorizador na coluna review do dataframe\n",
        "features_tfidf = vetorizador.fit_transform(df['review_cleaned'])\n",
        "\n",
        "#analise dos resultados\n",
        "print(\"informacoes do tf-idf criada\")\n",
        "\n",
        "#mostrando o formato da matriz resultante\n",
        "print(f\"matriz de features: {features_tfidf.shape}\")\n",
        "print(f\"tem {features_tfidf.shape[0]} documentos [reviews] e {features_tfidf.shape[1]} features [termos unicos ou n-gramas].\")\n",
        "\n",
        "#mostrando algumas das palavras\n",
        "nomes_das_features = vetorizador.get_feature_names_out()\n",
        "print(\"amostra de 20 features [palavras/termos]=\")\n",
        "print(nomes_das_features[5000:5020])\n",
        "print(\"\\n\")\n",
        "\n",
        "print(\"mostrando trecho [5x10] da matriz tf-idf c/ scores=\")\n",
        "df_tfidf_amostra = pd.DataFrame(\n",
        "    features_tfidf[0:5, 5000:5010].toarray(),\n",
        "    columns=nomes_das_features[5000:5010]\n",
        ")\n",
        "print(df_tfidf_amostra.round(2))\n",
        "\n",
        "total_elementos = features_tfidf.shape[0] * features_tfidf.shape[1]\n",
        "elementos_nao_nulos = features_tfidf.nnz\n",
        "\n",
        "porcentagem_nao_nulos = (elementos_nao_nulos / total_elementos) * 100\n",
        "porcentagem_nulos = 100 - porcentagem_nao_nulos\n",
        "\n",
        "print(f\"analise de esparsidade\")\n",
        "print(f\"a matriz tem {elementos_nao_nulos} valores diferentes de zero.\")\n",
        "print(f\"porcentagem de valores nao-null: {porcentagem_nao_nulos:.3f}%\")\n",
        "print(f\"porcentagem de valores null [0]: {porcentagem_nulos:.3f}%\")\n",
        "\n",
        "\n",
        "print(\"=============================================================================================================\")\n",
        "print(\"==================================== Modelagem de topicos com lda ===========================================\")\n",
        "print(\"=============================================================================================================\")\n",
        "\n",
        "print(\"2) Modelagem de Tópicos com LDA: Aplicar o algoritmo LDA para identificar tópicos prevalentes nos dados. A seleção do número de tópicos será baseada em métricas de coerência para garantir a relevância e a distinção entre os tópicos identificados.\")\n",
        "\n",
        "\n",
        "print(\"vetorizando os dados com countvectorizer\")\n",
        "vetorizador_contagem = CountVectorizer(\n",
        "    stop_words='english', # Removido pois o preprocessamento já cuida disso\n",
        "    max_features=10000,\n",
        "    min_df=5,\n",
        "    ngram_range=(1, 1)\n",
        ")\n",
        "features_contagem = vetorizador_contagem.fit_transform(df['review_cleaned'])\n",
        "nomes_features_contagem = vetorizador_contagem.get_feature_names_out()\n",
        "print(\"matriz de contagem de palavras criada com formato:\", features_contagem.shape)\n",
        "\n",
        "#encontrando o numero de topicos [k] com metricas de coerencia\n",
        "print(\"testando multiplos valores de k [numero de topicos] com metricas avacadas\")\n",
        "\n",
        "#preparando dados para o Gensim\n",
        "texts_tokenized = [doc.split() for doc in df['review_cleaned']]\n",
        "dictionary = Dictionary(texts_tokenized)\n",
        "dictionary.filter_extremes(no_below=5, no_above=0.5)\n",
        "\n",
        "min_topics = 2\n",
        "max_topics = 15\n",
        "topic_range = range(min_topics, max_topics + 1)\n",
        "\n",
        "log_likelihoods = []\n",
        "perplexities = []\n",
        "coherence_scores_cv = []\n",
        "\n",
        "for k in tqdm(topic_range, desc=\"Avaliando modelos LDA\"):\n",
        "    lda = LatentDirichletAllocation(\n",
        "        n_components=k,\n",
        "        random_state=42,\n",
        "        n_jobs=-1,\n",
        "        learning_method='online'\n",
        "    )\n",
        "    lda.fit(features_contagem)\n",
        "\n",
        "    log_likelihoods.append(lda.score(features_contagem))\n",
        "    perplexities.append(lda.perplexity(features_contagem))\n",
        "\n",
        "    #calculo da coerencia C_v\n",
        "    topics_words = []\n",
        "    for topic in lda.components_:\n",
        "        top_words_idx = topic.argsort()[:-15 - 1:-1]\n",
        "        topics_words.append([nomes_features_contagem[i] for i in top_words_idx])\n",
        "\n",
        "    coherence_model = CoherenceModel(\n",
        "        topics=topics_words, texts=texts_tokenized, dictionary=dictionary, coherence='c_v'\n",
        "    )\n",
        "    coherence_scores_cv.append(coherence_model.get_coherence())\n",
        "\n",
        "#visualizacao das metricas para escolha de k\n",
        "print(\"visualizando as metricas para a escolha do numero de topicos\")\n",
        "fig, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize=(21, 6))\n",
        "\n",
        "ax1.plot(topic_range, log_likelihoods, 'o-', color='darkblue')\n",
        "ax1.set_title('log-likelihood vs. numero de topicos')\n",
        "ax1.set_xlabel('numero de topicos [k]')\n",
        "ax1.set_ylabel('log-likelihood [maior eh melhor]')\n",
        "ax1.set_xticks(topic_range)\n",
        "\n",
        "ax2.plot(topic_range, perplexities, 'o-', color='crimson')\n",
        "ax2.set_title('perplexidade x numero de topicos')\n",
        "ax2.set_xlabel('numero de topicos [k]')\n",
        "ax2.set_ylabel('perplexidade [menor eh melhor]')\n",
        "ax2.set_xticks(topic_range)\n",
        "\n",
        "ax3.plot(topic_range, coherence_scores_cv, 'o-', color='forestgreen')\n",
        "ax3.set_title('coerencia de topicos [C_v]')\n",
        "ax3.set_xlabel('numero de topicos [k]')\n",
        "ax3.set_ylabel('coherence score [Maior é melhor]')\n",
        "ax3.set_xticks(topic_range)\n",
        "\n",
        "plt.suptitle('analise para selecao do numero de topicos [k] do LDA', fontsize=16)\n",
        "plt.tight_layout(rect=[0, 0, 1, 0.96])\n",
        "plt.show()\n",
        "\n",
        "#treinamento do modelo LDA final com o k escolhido\n",
        "print(\"justificativa da escolha e treinamento do modelo final\")\n",
        "best_k_index = np.argmax(coherence_scores_cv)\n",
        "num_topicos_ideal = topic_range[best_k_index]\n",
        "print(f\"com base na metrica de coerencia C_v, o valor otimo de topicos e {num_topicos_ideal}, onde o score foi maximo.\")\n",
        "\n",
        "print(f\"treinando o modelo LDA final com k={num_topicos_ideal} topicos\")\n",
        "lda_final = LatentDirichletAllocation(\n",
        "    n_components=num_topicos_ideal,\n",
        "    random_state=42,\n",
        "    n_jobs=-1,\n",
        "    learning_method='online'\n",
        ")\n",
        "lda_final.fit(features_contagem)\n",
        "print(\"modelo lda final treinado.\")\n",
        "\n",
        "def exibir_topicos(modelo, feature_names, n_top_words):\n",
        "    for topic_idx, topic in enumerate(modelo.components_):\n",
        "        top_features_ind = topic.argsort()[:-n_top_words - 1:-1]\n",
        "        top_features = [feature_names[i] for i in top_features_ind]\n",
        "        message = f\"topico #{topic_idx}: \" + \", \".join(top_features)\n",
        "        print(message)\n",
        "\n",
        "print(f\"exibindo as 10 palavras mais importantes para cada um dos {num_topicos_ideal} topicos encontrados=\")\n",
        "exibir_topicos(lda_final, nomes_features_contagem, 10)\n",
        "\n",
        "\n",
        "#associar os topicos aos documentos originais\n",
        "print(\"exemplo p/ associar topicos a reviews especificos=\")\n",
        "distribuicao_topicos = lda_final.transform(features_contagem)\n",
        "topico_dominante = np.argmax(distribuicao_topicos, axis=1)\n",
        "\n",
        "for i in range(5):\n",
        "    print(f\"review #{i}:\")\n",
        "    print(df['review'][i][:200] + \"...\")\n",
        "    print(f\"topico dominante = {topico_dominante[i]}\")\n",
        "\n",
        "print(\"=============================================================================================================\")\n",
        "print(\"==================================== classificacao de texto c/ lda ==========================================\")\n",
        "print(\"=============================================================================================================\")\n",
        "\n",
        "print(\"3) Classificação de Textos: Desenvolver modelos de classificação para categorizar os textos com base nos tópicos identificados. Você pode escolher qualquer modelo aprendido ao longo do curso e deve escolher o melhor modelo usando as técnicas aprendidas, como busca de hiperparâmetros e validação cruzada\")\n",
        "\n",
        "\n",
        "print(\"preparando os dados p/ classificacao\")\n",
        "\n",
        "#features [X] sao as distribuicoes de topicos já calculada.\n",
        "X_topics = distribuicao_topicos\n",
        "print(f\"formato da matriz de features [X]: {X_topics.shape}\")\n",
        "\n",
        "#alvo [y] e a coluna [sentiment] do df\n",
        "#convertr de texto [positive/negative] p/ numeros [1/0].\n",
        "le = LabelEncoder()\n",
        "y_sentiment = le.fit_transform(df['sentiment'])\n",
        "print(f\"formato do vetor de alvo [y]: {y_sentiment.shape}\")\n",
        "print(f\"classes: {le.classes_} >> {le.transform(le.classes_)}\")\n",
        "\n",
        "#dividindo em conjuntos de treino e teste [80% para treino, 20% para teste]\n",
        "#stratify=y_sentiment p/ fazer com que a proporcao de reviews positivos/negativos seja a mesma nos dois conjuntos.\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X_topics,\n",
        "    y_sentiment,\n",
        "    test_size=0.2,\n",
        "    random_state=42,\n",
        "    stratify=y_sentiment\n",
        ")\n",
        "\n",
        "print(f\"tamanho do conjunto de treino: {X_train.shape[0]} amostras\")\n",
        "print(f\"tamanho do conjunto de teste: {X_test.shape[0]} amostras\")\n",
        "\n",
        "\n",
        "print(\"buscando o melhor modelo e hiperparametros com gridsearchcv\")\n",
        "\n",
        "#Modelo 1=Regressao Logistica\n",
        "#Modelo 2=Support Vector Machine (SVC)\n",
        "modelos = {\n",
        "    'LogisticRegression': {\n",
        "        'model': LogisticRegression(random_state=42, max_iter=1000),\n",
        "        'params': {\n",
        "            'C': [0.1, 1, 10, 100],\n",
        "            'solver': ['liblinear', 'saga']\n",
        "        }\n",
        "    },\n",
        "    'SVC': {\n",
        "        'model': SVC(random_state=42, probability=True),\n",
        "        'params': {\n",
        "            'C': [0.1, 1, 10],\n",
        "            'gamma': ['scale', 'auto'],\n",
        "            'kernel': ['rbf']\n",
        "        }\n",
        "    }\n",
        "}\n",
        "\n",
        "#definindo a estrategia de validacao cruzada estratificada [5 folds] p/ manter a proporção das classes em cada fold\n",
        "cv_strategy = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "best_models = {}\n",
        "\n",
        "#iterando sobre os modelos para realizar o GridSearchCV\n",
        "for model_name, config in modelos.items():\n",
        "    print(f\"iniciando busca para o modelo: {model_name}\")\n",
        "    grid_search = GridSearchCV(\n",
        "        estimator=config['model'],\n",
        "        param_grid=config['params'],\n",
        "        cv=cv_strategy,\n",
        "        scoring='accuracy', #otimizar\n",
        "        n_jobs=-1 #processador on\n",
        "    )\n",
        "    grid_search.fit(X_train, y_train)\n",
        "    print(f\"melhores hiperparametros= {grid_search.best_params_}\")\n",
        "    print(f\"melhor acuracia em validacao cruzada= {grid_search.best_score_:.4f}\")\n",
        "    best_models[model_name] = grid_search.best_estimator_\n",
        "\n",
        "#determinando modelos com o melhor desempenho\n",
        "best_score = -1\n",
        "best_model_name = \"\"\n",
        "for model_name, model in best_models.items():\n",
        "    score = model.score(X_test, y_test)\n",
        "    if score > best_score:\n",
        "        best_score = score\n",
        "        best_model_name = model_name\n",
        "\n",
        "final_model = best_models[best_model_name]\n",
        "\n",
        "print(f\"melhor modelo geral escolhido: {best_model_name}\")\n",
        "print(\"avaliando o desempenho do melhor modelo no conjunto de teste [dados nunca vistos]\")\n",
        "\n",
        "#fazendo previsoes nos dados de teste\n",
        "y_pred = final_model.predict(X_test)\n",
        "\n",
        "#exibindo o relatorio de classificacao completo\n",
        "print(\"relatorio de classificacao=\")\n",
        "print(classification_report(y_test, y_pred, target_names=le.classes_))\n",
        "\n",
        "#exibindo a matriz de confusao\n",
        "print(\"matriz de confusao=\")\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=le.classes_)\n",
        "disp.plot(cmap=plt.cm.Blues)\n",
        "plt.title(f'matriz de confusao para o modelo {best_model_name}')\n",
        "plt.show()\n",
        "\n",
        "print(\"#######################################################################################################\")\n",
        "print(\"treinando o modelo base com as features TF-IDF diretamente\")\n",
        "print(\"#######################################################################################################\")\n",
        "\n",
        "#dividir os dados TF-IDF em treino e teste\n",
        "X_tfidf_train, X_tfidf_test, y_train_tfidf, y_test_tfidf = train_test_split(\n",
        "    features_tfidf,    #usando features_tfidf\n",
        "    y_sentiment,\n",
        "    test_size=0.2,\n",
        "    random_state=42,\n",
        "    stratify=y_sentiment\n",
        ")\n",
        "\n",
        "print(f\"tamanho do conjunto de treino [TF-IDF]: {X_tfidf_train.shape[0]} amostras\")\n",
        "print(f\"tamanho do conjunto de teste [TF-IDF]: {X_tfidf_test.shape[0]} amostras\")\n",
        "\n",
        "\n",
        "#treinar um modelo c/ regressao logistica, que costuma performar bem com dados TF-IDF esparsos.\n",
        "print(\"treinando o modelo de regressao logistica com features TF-IDF.\")\n",
        "model_tfidf = LogisticRegression(C=10, solver='saga', random_state=42, max_iter=1000, n_jobs=-1)\n",
        "model_tfidf.fit(X_tfidf_train, y_train_tfidf)\n",
        "\n",
        "\n",
        "#avaliar o modelo TF-IDF no conjunto de teste\n",
        "print(\"avaliando o desempenho do modelo TF-IDF no conjunto de teste:\")\n",
        "y_pred_tfidf = model_tfidf.predict(X_tfidf_test)\n",
        "\n",
        "print(\"relatorio de classificacao [Modelo Base TF-IDF]:\")\n",
        "print(classification_report(y_test_tfidf, y_pred_tfidf, target_names=le.classes_))\n",
        "\n",
        "\n",
        "#comparacao final dos resultados\n",
        "print(\"#######################################################################################################\")\n",
        "print(\"comparacao final dos modelos\")\n",
        "print(\"#######################################################################################################\")\n",
        "\n",
        "print(f\"modelo baseado em topicos [LDA + {best_model_name}]:\")\n",
        "y_pred_topics = final_model.predict(X_test)\n",
        "print(classification_report(y_test, y_pred_topics, target_names=le.classes_))\n",
        "\n",
        "print(f\"modelo base [TF-IDF + LogisticRegression]:\")\n",
        "print(classification_report(y_test_tfidf, y_pred_tfidf, target_names=le.classes_))\n",
        "\n",
        "\n",
        "print(\"O modelo TF-IDF geralmente captura melhor a semântica para classificação de sentimento,\")\n",
        "print(\"enquanto o modelo LDA agrupa documentos por temas, o que pode ser menos direto para esta tarefa específica.\")\n",
        "\n",
        "\n",
        "\n",
        "print(\"=============================================================================================================\")\n",
        "print(\"======================================== avaliacao de desempenho ============================================\")\n",
        "print(\"=============================================================================================================\")\n",
        "\n",
        "\n",
        "print(\"4) Avaliação de Desempenho: O desempenho dos modelos de classificação será avaliado utilizando métricas como precisão, recall, F1-score e AUC-ROC.\")\n",
        "\n",
        "#analise do modelo Principal [LDA]\n",
        "print(f\"analise do modelo principal ({best_model_name} + LDA)\")\n",
        "print(\"=\"*40)\n",
        "\n",
        "y_pred_topics = final_model.predict(X_test)\n",
        "print(\"relatorio de classificacao [Modelo Principal]:\")\n",
        "print(classification_report(y_test, y_pred_topics, target_names=le.classes_))\n",
        "\n",
        "y_pred_proba_topics = final_model.predict_proba(X_test)[:, 1]\n",
        "auc_score_topics = roc_auc_score(y_test, y_pred_proba_topics)\n",
        "fpr_topics, tpr_topics, _ = roc_curve(y_test, y_pred_proba_topics)\n",
        "print(f\"AUC [Modelo Principal]: {auc_score_topics:.4f}\")\n",
        "\n",
        "\n",
        "#analise do modelo base [TF-IDF]\n",
        "print(f\"analise do modelo base [LogisticRegression + TF-IDF]\")\n",
        "\n",
        "y_pred_tfidf = model_tfidf.predict(X_tfidf_test)\n",
        "print(\"relatorio de classificacao [modelo base]:\")\n",
        "print(classification_report(y_test_tfidf, y_pred_tfidf, target_names=le.classes_))\n",
        "\n",
        "y_pred_proba_tfidf = model_tfidf.predict_proba(X_tfidf_test)[:, 1]\n",
        "auc_score_tfidf = roc_auc_score(y_test_tfidf, y_pred_proba_tfidf)\n",
        "fpr_tfidf, tpr_tfidf, _ = roc_curve(y_test_tfidf, y_pred_proba_tfidf)\n",
        "print(f\"AUC [modelo base]: {auc_score_tfidf:.4f}\")\n",
        "\n",
        "\n",
        "#plot comparativo da curva ROC\n",
        "print(\"grafico comparativo da curva ROC\")\n",
        "\n",
        "plt.figure(figsize=(10, 8))\n",
        "plt.plot(fpr_topics, tpr_topics, color='darkorange', lw=2,\n",
        "         label=f'modelo principal [LDA] [AUC = {auc_score_topics:.4f}]')\n",
        "plt.plot(fpr_tfidf, tpr_tfidf, color='blue', lw=2,\n",
        "         label=f'modelo base [TF-IDF] [AUC = {auc_score_tfidf:.4f}]')\n",
        "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--', label='Classificador Aleatório')\n",
        "plt.xlim([0.0, 1.0])\n",
        "plt.ylim([0.0, 1.05])\n",
        "plt.xlabel('taxa de falsos positivos (FPR)')\n",
        "plt.ylabel('taxa de verdadeiros positivos (TPR)')\n",
        "plt.title('comparacao da curva ROC entre modelos')\n",
        "plt.legend(loc=\"lower right\")\n",
        "plt.grid(True)\n",
        "plt.show()\n",
        "\n",
        "print(\"=============================================================================================================\")\n",
        "print(\"============================================== aplicar T-SNE ================================================\")\n",
        "print(\"=============================================================================================================\")\n",
        "\n",
        "\n",
        "print(\"5) Visualização com t-SNE: Aplicar a técnica de t-SNE para visualizar os agrupamentos de documentos.\")\n",
        "\n",
        "#5.1)Visualizacao t-SNE baseada nos topicos LDA (Baixa Dimensionalidade)\n",
        "\n",
        "print(\"5.1) Aplicando t-SNE nos topicos LDA.\")\n",
        "\n",
        "#usar uma amostra para uma execucao mais rapida\n",
        "sample_size = 5000\n",
        "np.random.seed(42)\n",
        "random_indices = np.random.choice(X_topics.shape[0], size=sample_size, replace=False)\n",
        "\n",
        "X_sample = X_topics[random_indices]\n",
        "y_sample = y_sentiment[random_indices]\n",
        "sentiment_labels = le.inverse_transform(y_sample)\n",
        "\n",
        "print(f\"executando t-SNE em uma amostra de {sample_size} documentos [baseado em {X_sample.shape[1]} topicos].\")\n",
        "tsne_lda = TSNE(n_components=2, random_state=42, perplexity=30, n_iter=1000, n_jobs=-1)\n",
        "tsne_lda_results = tsne_lda.fit_transform(X_sample)\n",
        "\n",
        "df_tsne_lda = pd.DataFrame({\n",
        "    'tsne_1': tsne_lda_results[:,0],\n",
        "    'tsne_2': tsne_lda_results[:,1],\n",
        "    'sentiment': sentiment_labels\n",
        "})\n",
        "\n",
        "plt.figure(figsize=(12, 8))\n",
        "sns.scatterplot(\n",
        "    x=\"tsne_1\", y=\"tsne_2\",\n",
        "    hue=\"sentiment\",\n",
        "    palette=sns.color_palette(\"hls\", 2),\n",
        "    data=df_tsne_lda,\n",
        "    legend=\"full\",\n",
        "    alpha=0.6\n",
        ")\n",
        "plt.title('visualização t-SNE do sentimento [baseado nos topicos LDA]', fontsize=16)\n",
        "plt.xlabel('componente t-SNE 1')\n",
        "plt.ylabel('componente t-SNE 2')\n",
        "plt.show()\n",
        "\n",
        "\n",
        "#5.2)Visualizacao t-SNE baseada nas features TF-IDF [alta dimensionalidade]\n",
        "\n",
        "print(\"5.2) Aplicando t-SNE nas FEATURES TF-IDF.\")\n",
        "\n",
        "#amostra dos dados TF-IDF usando os mesmos indices aleatorios\n",
        "X_tfidf_sample = features_tfidf[random_indices]\n",
        "\n",
        "#passo de pre-reducao com TruncatedSVD, para dados de alta dimensionalidade\n",
        "print(f\"executando truncatedSVD para pre-reduzir {X_tfidf_sample.shape[1]} features para 50\")\n",
        "from sklearn.decomposition import TruncatedSVD\n",
        "svd = TruncatedSVD(n_components=50, random_state=42)\n",
        "X_svd_sample = svd.fit_transform(X_tfidf_sample)\n",
        "\n",
        "print(f\"executando t-SNE na amostra de {sample_size} documentos [pre-reduzidos para 50-dim].\")\n",
        "tsne_tfidf = TSNE(n_components=2, random_state=42, perplexity=30, n_iter=1000, n_jobs=-1)\n",
        "tsne_tfidf_results = tsne_tfidf.fit_transform(X_svd_sample)\n",
        "\n",
        "df_tsne_tfidf = pd.DataFrame({\n",
        "    'tsne_1': tsne_tfidf_results[:,0],\n",
        "    'tsne_2': tsne_tfidf_results[:,1],\n",
        "    'sentiment': sentiment_labels #re-utilizando os labels da amostra\n",
        "})\n",
        "\n",
        "plt.figure(figsize=(12, 8))\n",
        "sns.scatterplot(\n",
        "    x=\"tsne_1\", y=\"tsne_2\",\n",
        "    hue=\"sentiment\",\n",
        "    palette=sns.color_palette(\"hls\", 2),\n",
        "    data=df_tsne_tfidf,\n",
        "    legend=\"full\",\n",
        "    alpha=0.6\n",
        ")\n",
        "plt.title('visualizacao t-SNE do sentimento [baseado nas features TF-IDF]', fontsize=16)\n",
        "plt.xlabel('componente t-SNE 1')\n",
        "plt.ylabel('Componente t-SNE 2')\n",
        "plt.show()\n",
        "\n",
        "print(\"a primeira mostra a separacao com base nos temas [LDA] e a segunda com base na importancia das palavras [TF-IDF].\")\n",
        "\n",
        "\n",
        "\n",
        "print(\"=============================================================================================================\")\n",
        "print(\"============================= interpretacao de modelos com SHAP e force-plot ================================\")\n",
        "print(\"=============================================================================================================\")\n",
        "\n",
        "\n",
        "print(\"6) Interpretação de Modelos com LIME, SHAP e Force-Plot: Utilizar SHAP para explicar as previsões individuais, identificando a contribuição de cada feature para a decisão do modelo. O force-plot será usado para visualizar essas contribuições de maneira agregada, oferecendo insights sobre a lógica de decisão do modelo.\")\n",
        "print(f\"iniciando a interpretacao do modelo '{best_model_name}' com SHAP.\")\n",
        "\n",
        "\n",
        "shap.initjs()\n",
        "\n",
        "background_data = shap.sample(X_train, 100)\n",
        "test_sample_data = shap.sample(X_test, 20)\n",
        "\n",
        "explainer = shap.KernelExplainer(lambda x: final_model.predict_proba(x)[:, 1], background_data)\n",
        "\n",
        "print(\"calculando os valores SHAP para um subconjunto de dados de teste.\")\n",
        "shap_values_sample = explainer.shap_values(test_sample_data)\n",
        "\n",
        "topic_feature_names = [f\"Tópico {i}\" for i in range(num_topicos_ideal)]\n",
        "\n",
        "print(\"escolhido o Force-Plot para explicar previsoes individuais\")\n",
        "print(\"analisando a previsao para a primeira instancia da nossa amostra de teste=\")\n",
        "display(shap.force_plot(explainer.expected_value, shap_values_sample[0], test_sample_data[0], feature_names=topic_feature_names))\n",
        "\n",
        "print(\"selecionado o summary plot para ver a influencia agregada das variaveis\")\n",
        "print(\"resume como cada topico impacta as previsoes do modelo em todo o subconjunto de teste\")\n",
        "shap.summary_plot(shap_values_sample, test_sample_data, feature_names=topic_feature_names)\n",
        "\n",
        "print(\"importancia media das features [Bar Plot]\")\n",
        "shap.summary_plot(shap_values_sample, test_sample_data, feature_names=topic_feature_names, plot_type=\"bar\")\n",
        "\n",
        "\n",
        "print(\"########################################################################################################################\")\n",
        "print(\"interpretação adicional com lime\")\n",
        "\n",
        "print(\"6.2) Interpretação de Modelos com LIME usado para entender quais palavras no texto bruto mais influenciaram a decisao do nosso melhor modelo.\")\n",
        "\n",
        "#funcao preditora para o LIME que encapsula o pipeline de pre-processamento\n",
        "def predictor_for_lime(texts_raw):\n",
        "    #faz com que o texto passe pelo pre-processamento do treino\n",
        "    processed_texts = [preprocess_text(text) for text in texts_raw]\n",
        "    #transforma usando o vetorizador ja treinado\n",
        "    features = vetorizador.transform(processed_texts)\n",
        "    #retorna as probabilidades do modelo\n",
        "    return model_tfidf.predict_proba(features)\n",
        "\n",
        "explainer_lime = LimeTextExplainer(class_names=le.classes_)\n",
        "\n",
        "idx_to_explain = 12\n",
        "\n",
        "#para o LIME c/ texto original para uma interpretacao humana\n",
        "_, review_test_original, _, _ = train_test_split(df['review'], y_sentiment, test_size=0.2, random_state=42, stratify=y_sentiment)\n",
        "text_instance_original = review_test_original.iloc[idx_to_explain]\n",
        "\n",
        "print(f\"explicando a review de indice {idx_to_explain}\")\n",
        "print(f\"texto original: {text_instance_original[:500]}...\")\n",
        "true_label = le.inverse_transform([y_test_tfidf[idx_to_explain]])[0]\n",
        "pred_label_prob = model_tfidf.predict_proba(X_tfidf_test[idx_to_explain].reshape(1, -1))\n",
        "pred_label = le.inverse_transform(np.argmax(pred_label_prob, axis=1))[0]\n",
        "print(f\"classe verdadeira  = '{true_label}'\")\n",
        "print(f\"previsao do modelo = '{pred_label}' (Prob: {np.max(pred_label_prob):.2f})\")\n",
        "\n",
        "#gerar e exibir a explicacao do LIME\n",
        "print(\"explicação LIME:\")\n",
        "explanation = explainer_lime.explain_instance(\n",
        "    text_instance_original,\n",
        "    classifier_fn=predictor_for_lime,\n",
        "    num_features=10\n",
        ")\n",
        "\n",
        "#esta visualizacao colorida destaca as palavras que mais contribuiram para a previsao, palavras em verde apoiam a previsao, palavras em vermelho contradizem.\n",
        "print(\"visualizacao da explicacao LIME:\")\n",
        "explanation.show_in_notebook(text=True)\n",
        "\n",
        "#################################################################################\n",
        "\n",
        "#explicacao do LIME para o modelo baseado em LDA[melhor modelo]\n",
        "print(\"\\n#############################################################################################################\")\n",
        "print(\"interpretação adicional com lime [para o modelo LDA]\")\n",
        "\n",
        "#necessario recriar a transformacao de texto bruto >> contagem de palavras >> distribuicao de topicos.\n",
        "def predictor_for_lime_lda(texts_raw):\n",
        "    #faz com que o texto passe pelo mesmo pré-processamento do treino LDA\n",
        "    processed_texts = [preprocess_text(text) for text in texts_raw]\n",
        "    #veetoriza o texto usando o vetorizador de contagem ja treinado\n",
        "    features = vetorizador_contagem.transform(processed_texts)\n",
        "    #transforma a matriz de contagem na distribuicao de topicos usando o LDA\n",
        "    topic_distribution = lda_final.transform(features)\n",
        "    #retorna as probabilidades do modelo final [LDA + SVC/LogReg]\n",
        "    return final_model.predict_proba(topic_distribution)\n",
        "\n",
        "#criar o explainer para o modelo baseado em LDA\n",
        "explainer_lime_lda = LimeTextExplainer(class_names=le.classes_)\n",
        "\n",
        "#selecionar uma instancia para explicar c/ mesmo conjunto de teste de reviews original\n",
        "#_, review_test_original, _, _ = train_test_split(df['review'], y_sentiment, test_size=0.2, random_state=42, stratify=y_sentiment)\n",
        "text_instance_original_lda = review_test_original.iloc[idx_to_explain]\n",
        "\n",
        "print(f\"explicando a review de indice {idx_to_explain} para o modelo LDA\")\n",
        "print(f\"texto original: {text_instance_original_lda[:500]}\")\n",
        "\n",
        "#fazer a previsao e exibir as informacoes\n",
        "true_label_lda = le.inverse_transform([y_test[idx_to_explain]])[0]\n",
        "pred_label_prob_lda = final_model.predict_proba(X_test[idx_to_explain].reshape(1, -1))\n",
        "pred_label_lda = le.inverse_transform(np.argmax(pred_label_prob_lda, axis=1))[0]\n",
        "print(f\"classe verdadeira  = '{true_label_lda}'\")\n",
        "print(f\"previsao do modelo = '{pred_label_lda}' [Prob: {np.max(pred_label_prob_lda):.2f}]\")\n",
        "\n",
        "#gerar e exibir a explicacao do LIME\n",
        "print(\"explicacao LIME:\")\n",
        "explanation_lda = explainer_lime_lda.explain_instance(\n",
        "    text_instance_original_lda,\n",
        "    classifier_fn=predictor_for_lime_lda,\n",
        "    num_features=10\n",
        ")\n",
        "\n",
        "# Visualizar a explicação do LIME\n",
        "print(\"visualizacao da explicacao LIME para o modelo LDA:\")\n",
        "explanation_lda.show_in_notebook(text=True)\n",
        "\n",
        "print(\"7) Análise dos resultados: Enumere as conclusões que podem ser tomadas a partir dos resultados obtidos.\")\n",
        "\n",
        "#Análise dos Resultados: Conclusões do Projeto\n",
        "#O desenvolvimento deste projeto percorreu um pipeline completo de Machine Learning, desde o pré-processamento de dados textuais até a criação, avaliação e visualização de modelos. A análise criteriosa dos resultados obtidos em cada etapa nos permite extrair insights relevantes.\n",
        "#A conclusão importante do projeto é a diferença de performance entre os modelos.\n",
        "\n",
        "#Análise da Matriz de Confusão para o modelo SVC ficou com o resultado de:\n",
        "#[ 3975 (Verdadeiros Positivos),\t1025 (Falsos Negativos),\n",
        "#Real Negativo 1331 (Falsos Positivos), 3669 (Verdadeiros Negativos)]\n",
        "\n",
        "#O classificador que utilizou features de alta dimensionalidade [TF-IDF] alcançou um desempenho excelente [90% de acurácia, 0.96 AUC], enquanto o modelo baseado em features temáticas de baixa dimensionalidade (LDA) obteve um resultado pior [76% de acurácia, 0.82 AUC].\n",
        "#Isso mostra que nesse caso a tarefa de análise de sentimento, a presença e a importância de palavras e frases específicas são sinais preditivos mais fortes do que o tema geral do texto. O processo de abstração do LDA, mesmo útil para outros fins, removeu a performance para uma classificação de alta precisão neste contexto.\n",
        "#Apesar de seu desempenho inferior como feature para classificação, o LDA modelou tópicos. O algoritmo identificou com sucesso 12 temas distintos e humanamente interpretáveis no corpus [ex: \"Filmes de Guerra\", \"Ficção Científica\", \"Comédias\"].\n",
        "#Na visualização t-SNE seu gráfico confirmou que esses tópicos possuem uma correlação real, ainda que parcial, com o sentimento se mostrando mais legível e organizado com clusters mais definidos. Enquanto o (TF-IDF) mostrou uma nuvem bagunçada.\n",
        "#O classificador TF-IDF (com 90% de sucesso) não se traduz necessariamente em clusters visualmente separáveis em 2D.\n",
        "\n",
        "#Resultado Comparativo\n",
        "#O Modelo Base [TF-IDF] supera o Modelo Principal [LDA] em todas as métricas avaliadas, tanto nas gerais [Acurácia, AUC] quanto nas específicas por classe [Precisão, Recall, F1-Score]."
      ]
    }
  ]
}